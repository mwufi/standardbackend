{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AsyncGeneratorResult(type='text', content='Here is how')\n",
      "AsyncGeneratorResult(type='text', content=' to call the generate')\n",
      "AsyncGeneratorResult(type='text', content='_task_plan')\n",
      "AsyncGeneratorResult(type='text', content=' tool with the given')\n",
      "AsyncGeneratorResult(type='text', content=' task description:')\n",
      "AsyncGeneratorResult(type='tool_use', content=ToolUseBlock(id='toolu_01BnKWiSr4EpHvQnpvMnaEJK', input={'task_description': 'write a blog post about the benefits of using tools in AI', 'task_plan': 'Task: Write a blog post about the benefits of using tools in AI\\n\\nSteps:\\n1. Research and gather information on the key benefits of using tools in AI applications and workflows. Some potential benefits to cover:\\n    - Increased efficiency and productivity \\n    - Access to specialized capabilities\\n    - Ability to automate repetitive tasks\\n    - Integration of multiple AI components\\n    - Scalability and flexibility\\n2. Outline the main sections and key points to cover in the blog post.\\n3. Write an introduction explaining what AI tools are and setting up the topic.\\n4. Write a section detailing each of the major benefits identified, with examples and use cases.\\n5. Write a conclusion summarizing the benefits and importance of leveraging AI tools.\\n6. Create eye-catching title and header images.\\n7. Review and edit the post for clarity, flow, and accuracy.\\n8. Publish the post on relevant blogging platforms and promote through social media channels.'}, name='generate_task_plan', type='tool_use'))\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, AsyncGenerator, Optional\n",
    "import anthropic\n",
    "from anthropic.types import Message, MessageParam, ToolUseBlock\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# Define a tool that takes in a task description and returns a task plan\n",
    "from standardbackend.tools.base import Tool\n",
    "from pydantic import BaseModel\n",
    "from standardbackend.tools.cache import ToolCache\n",
    "\n",
    "class TaskPlan(BaseModel):\n",
    "    task_description: str\n",
    "    task_plan: str\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"generate_task_plan\",\n",
    "        description=\"Generate a detailed execution plan for a task\",\n",
    "        input_schema=TaskPlan,\n",
    "        execute=lambda x: \"Success! You can print the results as-is\",\n",
    "    )\n",
    "]\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Union\n",
    "\n",
    "@dataclass\n",
    "class AsyncGeneratorResult:\n",
    "    \"\"\"Represents a result from the async generator stream\"\"\"\n",
    "    type: str  # Can be 'text' or 'tool_use'\n",
    "    content: Union[str, dict]  # Either text content or tool result dictionary\n",
    "\n",
    "class Claude:\n",
    "    def __init__(self, api_key: Optional[str] = None, model: str = \"claude-3-sonnet-20240229\", tools: List[Tool] = tools):\n",
    "        self.client = anthropic.AsyncAnthropic(api_key=api_key) if api_key else anthropic.AsyncAnthropic()\n",
    "        self.model = model\n",
    "        self.tools = tools\n",
    "        self.tool_cache = ToolCache(tools)\n",
    "\n",
    "    async def stream_chat(\n",
    "        self,\n",
    "        messages: List[Dict[str, str]],\n",
    "        max_tokens: int = 4096,\n",
    "        temperature: float = 0.7,\n",
    "    ) -> AsyncGenerator[str, None]:\n",
    "        \"\"\"\n",
    "        Handles streaming events from the Anthropic API\n",
    "        \n",
    "        We return a bunch of str events\n",
    "        \"\"\"\n",
    "        \n",
    "        def handle_streaming_tool_use(block: ToolUseBlock):\n",
    "            # Schedule and execute tool\n",
    "            self.tool_cache.request_execution(block.id, block.name, block.input)\n",
    "            # result = self.tool_cache.get(block.id)\n",
    "            return AsyncGeneratorResult(type=\"tool_use\", content=block)\n",
    "\n",
    "        def handle_streaming_text_end(text: str):\n",
    "            pass\n",
    "\n",
    "        def handle_streaming_text_partial(text_delta: str):\n",
    "            return AsyncGeneratorResult(type=\"text\", content=text_delta)\n",
    "\n",
    "        def handle_streaming_tool_use_partial(partial_json):\n",
    "            \"\"\"We don't use partial json. But in some cases, like UI generation, it can be useful\"\"\"\n",
    "            pass \n",
    "\n",
    "        def unhandled_event(event):\n",
    "            \"\"\"Useful for debugging\n",
    "\n",
    "            Example:\n",
    "\n",
    "            if event.type not in ['text', 'input_json', 'message_stop']:\n",
    "                print(\"---> unhandled\", event.type, event)\n",
    "            \"\"\"\n",
    "            pass\n",
    "\n",
    "        def process_event(event):\n",
    "            if event.type == 'message_start':\n",
    "                pass\n",
    "            elif event.type == 'content_block_start':\n",
    "                # This just tells us what kind of content block we're dealing with\n",
    "                # RawContentBlockStartEvent(content_block=TextBlock(text='', type='text'), index=0, type='content_block_start')\n",
    "                # RawContentBlockStartEvent(content_block=ToolUseBlock(id='toolu_01S2mZDhjnHMmH1QbMkyRgw4', input={}, name='generate_task_plan', type='tool_use'), index=1, type='content_block_start')\n",
    "                pass\n",
    "            elif event.type == 'content_block_delta':\n",
    "                delta = event.delta\n",
    "                if delta.type == 'text_delta':\n",
    "                    return handle_streaming_text_partial(delta.text)\n",
    "                elif delta.type == 'input_json_delta':\n",
    "                    return handle_streaming_tool_use_partial(delta.partial_json)\n",
    "                else:\n",
    "                    unhandled_event(event)\n",
    "            elif event.type == 'content_block_stop':\n",
    "                content_block = event.content_block\n",
    "                if content_block.type == 'text':\n",
    "                    return handle_streaming_text_end(content_block.text)\n",
    "                elif content_block.type == 'tool_use':\n",
    "                    return handle_streaming_tool_use(content_block)\n",
    "                else:\n",
    "                    unhandled_event(event)\n",
    "            else:\n",
    "                unhandled_event(event)\n",
    "            \n",
    "        async with self.client.messages.stream(\n",
    "            max_tokens=max_tokens,\n",
    "            messages=messages,\n",
    "            model=self.model,\n",
    "            temperature=temperature,\n",
    "            tools=self.tool_cache.tool_specs,\n",
    "        ) as stream:\n",
    "            async for event in stream:\n",
    "                processed_event = process_event(event)\n",
    "                if processed_event:\n",
    "                    yield processed_event\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"call the tool generate_task_plan with the task description 'write a blog post about the benefits of using tools in AI' and print the results\"}\n",
    "]\n",
    "\n",
    "claude = Claude()\n",
    "async for event in claude.stream_chat(messages):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
