{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from anthropic import Anthropic\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextAnalysis(BaseModel):\n",
    "    sentiment: str = Field(description=\"Overall sentiment of the text (positive, negative, or neutral)\")\n",
    "    main_topics: List[str] = Field(description=\"List of main topics in the text\")\n",
    "    word_count: int = Field(description=\"Total word count of the text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Claude tool use can be quite useful if used correctly.\n",
      "Analyzing text...\n",
      "\n",
      "Sentiment: positive\n",
      "Main topics: tool use, Claude\n",
      "Word count: 10\n"
     ]
    }
   ],
   "source": [
    "def analyze_text_with_claude(api_key: str, text: str) -> TextAnalysis:\n",
    "    client = Anthropic(api_key=api_key)\n",
    " \n",
    "    text_analysis_schema = TextAnalysis.model_json_schema()\n",
    " \n",
    "    tools = [\n",
    "        {\n",
    "            \"name\": \"build_text_analysis_result\",\n",
    "            \"description\": \"build the text analysis object\",\n",
    "            \"input_schema\": text_analysis_schema\n",
    "        }\n",
    "    ]\n",
    " \n",
    "    message = client.messages.create(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=1200,\n",
    "        temperature=0.2,\n",
    "        system=\"You are analyzing the sentiment of a text.\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{text}\"\n",
    "            }\n",
    "        ],\n",
    "        tools=tools,\n",
    "        tool_choice={\"type\": \"tool\", \"name\": \"build_text_analysis_result\"}\n",
    "    )\n",
    " \n",
    "    function_call = message.content[0].input\n",
    "    return TextAnalysis(**function_call)\n",
    "\n",
    "# test it out!\n",
    "api_key = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "sample_text = \"Claude tool use can be quite useful if used correctly.\"\n",
    " \n",
    "print(f\"Text: {sample_text}\\nAnalyzing text...\\n\")\n",
    "analysis = analyze_text_with_claude(api_key, sample_text)\n",
    "print(f\"Sentiment: {analysis.sentiment}\")\n",
    "print(f\"Main topics: {', '.join(analysis.main_topics)}\")\n",
    "print(f\"Word count: {analysis.word_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Anthropic models:\n",
      "- claude-3-5-sonnet-20241022\n",
      "- claude-3-5-haiku-20241022\n",
      "- claude-3-5-sonnet-20240620\n",
      "- claude-3-haiku-20240307\n",
      "- claude-3-opus-20240229\n",
      "- claude-3-sonnet-20240229\n",
      "- claude-2.1\n",
      "- claude-2.0\n"
     ]
    }
   ],
   "source": [
    "def list_anthropic_models(api_key: str) -> List[str]:\n",
    "    client = Anthropic(api_key=api_key)\n",
    "    models = client.models.list()\n",
    "    return [model.id for model in models]  # Use id instead of name\n",
    "\n",
    "# Test it out\n",
    "models = list_anthropic_models(os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "print(\"Available Anthropic models:\")\n",
    "for model in models:\n",
    "    print(f\"- {model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's add our Pydantic models\n",
    "class Step(BaseModel):\n",
    "    action: str\n",
    "    inputs: List[str]\n",
    "    outputs: List[str]\n",
    "    constraints: List[str] = Field(default_factory=list)\n",
    "\n",
    "class ActionPattern(BaseModel):\n",
    "    type: str\n",
    "    frequency: str\n",
    "    steps: List[Step]\n",
    "\n",
    "class CurrentState(BaseModel):\n",
    "    resources: dict = Field(default_factory=dict)\n",
    "    constraints: dict = Field(default_factory=dict)\n",
    "    progress_metrics: dict = Field(default_factory=dict)\n",
    "\n",
    "class ExecutionStrategy(BaseModel):\n",
    "    cycle: str\n",
    "    checkpoints: List[str]\n",
    "    memory_requirements: List[str]\n",
    "\n",
    "class TaskPlan(BaseModel):\n",
    "    goal: str\n",
    "    success_metric: str\n",
    "    current_state: CurrentState\n",
    "    execution_strategy: ExecutionStrategy\n",
    "    action_patterns: List[ActionPattern]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's fix the generate_task_plan function\n",
    "def generate_task_plan(api_key: str, task_description: str) -> TaskPlan:\n",
    "    client = Anthropic(api_key=api_key)\n",
    "    \n",
    "    task_plan_schema = TaskPlan.model_json_schema()\n",
    "    \n",
    "    tools = [\n",
    "        {\n",
    "            \"name\": \"build_task_plan\",\n",
    "            \"description\": \"Build a structured execution plan for any task with clear steps and requirements\",\n",
    "            \"input_schema\": task_plan_schema\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=1500,\n",
    "        temperature=0.2,\n",
    "        system=\"You are a task planning expert who breaks down complex tasks into detailed, actionable steps.\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Create a detailed execution plan for the following task: {task_description}\"\n",
    "            }\n",
    "        ],\n",
    "        tools=tools,\n",
    "        tool_choice={\"type\": \"tool\", \"name\": \"build_task_plan\"}\n",
    "    )\n",
    "\n",
    "    return TaskPlan(**message.content[0].input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task: Research and compile healthy vegetarian dinner recipes for a week\n",
      "--------------------------------------------------\n",
      "{\n",
      "  \"goal\": \"Research and compile healthy vegetarian dinner recipes for a week\",\n",
      "  \"success_metric\": \"Have a set of 7 healthy vegetarian dinner recipes to cook for the week\",\n",
      "  \"current_state\": {\n",
      "    \"resources\": {\n",
      "      \"time_available\": \"1 week\",\n",
      "      \"cooking_experience\": \"intermediate\"\n",
      "    },\n",
      "    \"constraints\": {\n",
      "      \"dietary_restrictions\": \"vegetarian\"\n",
      "    },\n",
      "    \"progress_metrics\": {\n",
      "      \"number_of_recipes_found\": 0\n",
      "    }\n",
      "  },\n",
      "  \"execution_strategy\": {\n",
      "    \"cycle\": \"daily\",\n",
      "    \"checkpoints\": [\n",
      "      \"Identify recipe sources\",\n",
      "      \"Compile list of potential recipes\",\n",
      "      \"Evaluate recipes for health and feasibility\",\n",
      "      \"Select 7 recipes\"\n",
      "    ],\n",
      "    \"memory_requirements\": [\n",
      "      \"list of recipe sources\",\n",
      "      \"list of potential recipes\",\n",
      "      \"evaluation criteria for recipes\"\n",
      "    ]\n",
      "  },\n",
      "  \"action_patterns\": [\n",
      "    {\n",
      "      \"type\": \"Research\",\n",
      "      \"frequency\": \"daily\",\n",
      "      \"steps\": [\n",
      "        {\n",
      "          \"action\": \"Identify online recipe sources\",\n",
      "          \"inputs\": [],\n",
      "          \"outputs\": [\n",
      "            \"list of recipe websites\"\n",
      "          ],\n",
      "          \"constraints\": [\n",
      "            \"vegetarian\",\n",
      "            \"healthy\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"action\": \"Search for potential recipes\",\n",
      "          \"inputs\": [\n",
      "            \"list of recipe websites\"\n",
      "          ],\n",
      "          \"outputs\": [\n",
      "            \"list of potential recipes\"\n",
      "          ],\n",
      "          \"constraints\": [\n",
      "            \"vegetarian\",\n",
      "            \"healthy\",\n",
      "            \"dinner\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"action\": \"Evaluate recipes for health and feasibility\",\n",
      "          \"inputs\": [\n",
      "            \"list of potential recipes\"\n",
      "          ],\n",
      "          \"outputs\": [\n",
      "            \"list of selected recipes\"\n",
      "          ],\n",
      "          \"constraints\": [\n",
      "            \"vegetarian\",\n",
      "            \"healthy\",\n",
      "            \"dinner\",\n",
      "            \"ingredients available\",\n",
      "            \"preparation time\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Compilation\",\n",
      "      \"frequency\": \"end of week\",\n",
      "      \"steps\": [\n",
      "        {\n",
      "          \"action\": \"Select 7 recipes from the list\",\n",
      "          \"inputs\": [\n",
      "            \"list of selected recipes\"\n",
      "          ],\n",
      "          \"outputs\": [\n",
      "            \"set of 7 recipes\"\n",
      "          ],\n",
      "          \"constraints\": [\n",
      "            \"vegetarian\",\n",
      "            \"healthy\",\n",
      "            \"dinner\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "task = \"Research and compile healthy vegetarian dinner recipes for a week\"\n",
    "print(f\"\\nTask: {task}\")\n",
    "print(\"-\" * 50)\n",
    "plan = generate_task_plan(os.getenv(\"ANTHROPIC_API_KEY\"), task)\n",
    "print(json.dumps(plan.model_dump(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we're going to build an agentic agent that can do tasks by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='run_python_code', description='Run Python code with configurable timeout and output limits', input_schema=<class 'standardbackend.tools.python_code_runner.EvalInput'>, execute=<function execute_python_code at 0x10cf436a0>)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from standardbackend.tools.python_code_runner import tools as python_code_runner_tools\n",
    "python_code_runner_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = python_code_runner_tools\n",
    "\n",
    "# Convert to dict format when needed\n",
    "tool_dicts = [tool.to_dict() for tool in tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing basic printing...\n",
      "Hello world!\n",
      "Numbers: 2\n",
      "Multiple\n",
      "lines\n",
      "test\n",
      "\n",
      "\n",
      "Testing directory listing...\n",
      "Current directory contents:\n",
      "hello.ipynb\n",
      "\n",
      "\n",
      "Testing system memory info...\n",
      "Total RAM: 16.0 GB\n",
      "Available RAM: 3.0 GB\n",
      "RAM Usage: 81.5%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from standardbackend.tools.python_code_runner import execute_python_code, EvalInput\n",
    "\n",
    "# Test printing\n",
    "print(\"Testing basic printing...\")\n",
    "r = execute_python_code(EvalInput(code=\"print('Hello world!')\\nprint(f'Numbers: {1+1}')\\nprint('Multiple\\\\nlines\\\\ntest')\"))\n",
    "print(r)\n",
    "\n",
    "# Test directory listing\n",
    "print(\"\\nTesting directory listing...\")\n",
    "r = execute_python_code(EvalInput(code=\"\"\"\n",
    "import os\n",
    "print('Current directory contents:')\n",
    "print('\\\\n'.join(os.listdir('.')))\n",
    "\"\"\"))\n",
    "print(r)\n",
    "\n",
    "# Test system RAM info\n",
    "print(\"\\nTesting system memory info...\")\n",
    "r = execute_python_code(EvalInput(code=\"\"\"\n",
    "import psutil\n",
    "mem = psutil.virtual_memory()\n",
    "print(f'Total RAM: {mem.total / (1024**3):.1f} GB')\n",
    "print(f'Available RAM: {mem.available / (1024**3):.1f} GB') \n",
    "print(f'RAM Usage: {mem.percent}%')\n",
    "\"\"\"))\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'python_code_runner',\n",
       " 'description': 'Run Python code with configurable timeout and output limits',\n",
       " 'input_schema': {'properties': {'code': {'title': 'Code', 'type': 'string'},\n",
       "   'timeout': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "    'default': 30,\n",
       "    'title': 'Timeout'},\n",
       "   'max_output_length': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "    'default': 1000,\n",
       "    'title': 'Max Output Length'}},\n",
       "  'required': ['code'],\n",
       "  'title': 'EvalInput',\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember to call to_dict() on the tool to get the dictionary representation\n",
    "tools[0].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to use tools?\n",
    "\n",
    "Extract tool input(s), run code, and return results: (API request)\n",
    "\n",
    "On the client side, you should extract the tool name and input(s) from Claude's tool use request.\n",
    "Run the actual tool code on the client side.\n",
    "Return the results to Claude by continuing the conversation with a new user message containing a tool_result content block.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is how we can check the amount of memory available in the current environment:\n",
      "[tool_use] run_python_code toolu_01Q8sFHK3EnUoohV1vfzHNf6\n",
      "=>  {'code': 'import psutil\\n\\ntotal_memory = psutil.virtual_memory().total\\nprint(f\"Total memory: {total_memory / (1024 ** 2):.2f} MB\")'}\n",
      "[tool_answer] Total memory: 16384.00 MB\n",
      "\n",
      "Message(id='msg_018XHYaQRDBURUvsCTY5wyRd', content=[TextBlock(text='Here is how we can check the amount of memory available in the current environment:', type='text'), ToolUseBlock(id='toolu_01Q8sFHK3EnUoohV1vfzHNf6', input={'code': 'import psutil\\n\\ntotal_memory = psutil.virtual_memory().total\\nprint(f\"Total memory: {total_memory / (1024 ** 2):.2f} MB\")'}, name='run_python_code', type='tool_use')], model='claude-3-haiku-20240307', role='assistant', stop_reason='tool_use', stop_sequence=None, type='message', usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=439, output_tokens=116))\n"
     ]
    }
   ],
   "source": [
    "from anthropic import Anthropic\n",
    "import os\n",
    "from standardbackend.tools import ExecutionStatus, ToolCache\n",
    "from standardbackend.tools.python_code_runner import tools as python_tools\n",
    "\n",
    "client = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "tool_cache = ToolCache(python_tools)\n",
    "\n",
    "def answer_question(question: str):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"How much memory do I have right now? Be sure to use the tool!\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    claude_message = client.messages.create(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=1200,\n",
    "        temperature=0.2,\n",
    "        tools=tool_cache.tool_specs,\n",
    "        # tool_choice={\"type\": \"tool\", \"name\": \"python_code_runner\"},\n",
    "        tool_choice={\"type\": \"auto\"},\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    def parse_message(message):\n",
    "        \"\"\"Can return metadata, but for now we just build the response messages directly\"\"\"\n",
    "        metadata = {\n",
    "            'tools_called': []\n",
    "        }\n",
    "        tool_responses = []\n",
    "\n",
    "        def handle_text_output(block):\n",
    "            print(block.text)\n",
    "        \n",
    "        def handle_tool_use(block):\n",
    "            print(f\"[tool_use] {block.name} {block.id}\")\n",
    "            print(\"=> \", block.input)\n",
    "\n",
    "            # Schedule execution - right now it executes immediately\n",
    "            ans = tool_cache.request_execution(block.id, block.name, block.input)\n",
    "\n",
    "            # Get the result!\n",
    "            ans = tool_cache.get(block.id)\n",
    "\n",
    "            if ans.status == ExecutionStatus.COMPLETED:\n",
    "                tool_responses.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                        \"type\": \"tool_result\",\n",
    "                        \"tool_use_id\": block.id,\n",
    "                        \"content\": ans.result\n",
    "                        }\n",
    "                    ]\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Tool {block.id} failed with error: {ans.error}\")\n",
    "            \n",
    "            # sure, print it\n",
    "            print(f\"[tool_answer] {ans.result}\")\n",
    "\n",
    "\n",
    "        for block in message.content:\n",
    "            content_type = block.type\n",
    "            if content_type == \"text\":\n",
    "                handle_text_output(block)\n",
    "            elif content_type == \"tool_use\":\n",
    "                handle_tool_use(block)\n",
    "                metadata['tools_called'].append(block.id)\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected message type: {content_type}\")\n",
    "        \n",
    "        return metadata, tool_responses\n",
    "    \n",
    "    metadata, tool_responses = parse_message(claude_message)\n",
    "    \n",
    "    # add stuff to the conversation\n",
    "    messages.append(claude_message)\n",
    "    print(claude_message)\n",
    "    messages.extend(tool_responses)\n",
    "\n",
    "    return messages\n",
    "\n",
    "messages = answer_question(\"How much memory do I have right now?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm.. do we want to have threads be a composite of Message and json types?\n",
    "\n",
    "```\n",
    "Message(id='msg_018XHYaQRDBURUvsCTY5wyRd', content=[TextBlock(text='Here is how we can check the amount of memory available in the current environment:', type='text'), ToolUseBlock(id='toolu_01Q8sFHK3EnUoohV1vfzHNf6', input={'code': 'import psutil\\n\\ntotal_memory = psutil.virtual_memory().total\\nprint(f\"Total memory: {total_memory / (1024 ** 2):.2f} MB\")'}, name='run_python_code', type='tool_use')], model='claude-3-haiku-20240307', role='assistant', stop_reason='tool_use', stop_sequence=None, type='message', usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=439, output_tokens=116))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversation:\n",
      "\u001b[1m\u001b[32m\n",
      "[User]\u001b[0m\n",
      "How much memory do I have right now? Be sure to use the tool!\n",
      "\u001b[1m\u001b[34m\n",
      "[Assistant]\u001b[0m\n",
      "Here is how we can check the amount of memory available in the current environment:\n",
      "\u001b[1m\u001b[35m\n",
      "[Tool Use]\u001b[0m\n",
      "Tool: run_python_code\n",
      "Input: {'code': 'import psutil\\n\\ntotal_memory = psutil.virtual_memory().total\\nprint(f\"Total memory: {total_memory / (1024 ** 2):.2f} MB\")'}\n",
      "\u001b[1m\u001b[32m\n",
      "[User]\u001b[0m\n",
      "\u001b[1m\u001b[33m\n",
      "[Tool Result]\u001b[0m\n",
      "Total memory: 16384.00 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def pretty_print_messages(messages):\n",
    "    \"\"\"Pretty print conversation messages with color coding\"\"\"\n",
    "    from termcolor import colored\n",
    "    \n",
    "    for msg in messages:\n",
    "        # Handle both dict and Message objects\n",
    "        if isinstance(msg, dict):\n",
    "            role = msg['role']\n",
    "            content = msg['content']\n",
    "        else:\n",
    "            role = msg.role\n",
    "            content = msg.content\n",
    "        \n",
    "        # Print role header\n",
    "        if role == 'user':\n",
    "            print(colored(f\"\\n[User]\", 'green', attrs=['bold']))\n",
    "        elif role == 'assistant':\n",
    "            print(colored(f\"\\n[Assistant]\", 'blue', attrs=['bold']))\n",
    "        \n",
    "        # Handle different content types\n",
    "        if isinstance(content, str):\n",
    "            # Simple text content\n",
    "            print(content)\n",
    "        elif isinstance(content, list):\n",
    "            # Complex content with blocks\n",
    "            for block in content:\n",
    "                if isinstance(block, dict):\n",
    "                    # Tool result block\n",
    "                    if block['type'] == 'tool_result':\n",
    "                        print(colored(\"\\n[Tool Result]\", 'yellow', attrs=['bold']))\n",
    "                        print(block['content'])\n",
    "                    # Message block from assistant\n",
    "                    elif block['type'] == 'text':\n",
    "                        print(block['text'])\n",
    "                    elif block['type'] == 'tool_use':\n",
    "                        print(colored(\"\\n[Tool Use]\", 'magenta', attrs=['bold']))\n",
    "                        print(f\"Tool: {block['name']}\")\n",
    "                        print(f\"Input: {block['input']}\")\n",
    "                else:\n",
    "                    # Handle typed blocks\n",
    "                    if block.type == 'tool_result':\n",
    "                        print(colored(\"\\n[Tool Result]\", 'yellow', attrs=['bold']))\n",
    "                        print(block.content)\n",
    "                    elif block.type == 'text':\n",
    "                        print(block.text)\n",
    "                    elif block.type == 'tool_use':\n",
    "                        print(colored(\"\\n[Tool Use]\", 'magenta', attrs=['bold']))\n",
    "                        print(f\"Tool: {block.name}\")\n",
    "                        print(f\"Input: {block.input}\")\n",
    "\n",
    "print(\"\\nConversation:\")\n",
    "pretty_print_messages(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize, I do not have direct access to information about your computer's memory. As an AI assistant without direct access to your device, I do not have the ability to retrieve details about your system's hardware specifications. I can only provide information based on what you directly share with me or what is available in my general knowledge. If you would like to check the amount of memory on your computer, you would need to use tools or commands specific to your operating system. Let me know if there are any other ways I can try to assist you!\n",
      "\u001b[1m\u001b[32m\n",
      "[User]\u001b[0m\n",
      "How much memory do I have right now?\n",
      "\u001b[1m\u001b[34m\n",
      "[Assistant]\u001b[0m\n",
      "I apologize, I do not have direct access to information about your computer's memory. As an AI assistant without direct access to your device, I do not have the ability to retrieve details about your system's hardware specifications. I can only provide information based on what you directly share with me or what is available in my general knowledge. If you would like to check the amount of memory on your computer, you would need to use tools or commands specific to your operating system. Let me know if there are any other ways I can try to assist you!\n"
     ]
    }
   ],
   "source": [
    "from standardbackend.helpers.thread import Thread\n",
    "\n",
    "# Basic usage - checking system memory\n",
    "thread = Thread()\n",
    "messages = thread.send_message(\"How much memory do I have right now?\")\n",
    "pretty_print_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<thinking>\n",
      "The provided tool run_python_code seems relevant for writing a short story about a programmer debugging code. The required parameter is:\n",
      "\n",
      "code (string): This would be the Python code to execute to generate the story. \n",
      "\n",
      "Since the user did not provide the actual code to run, I do not have enough information to call the tool directly. The user's request was to write a story, not to debug or run a specific piece of code. So I don't think I can reasonably infer the code parameter in this case.\n",
      "\n",
      "To fully address the user's request, I will write the story directly in my response without using the run_python_code tool, since I have the ability to generate a story on my own without needing to execute Python code.\n",
      "</thinking>\n",
      "\n",
      "Here is a short story about a programmer debugging code:\n",
      "\n",
      "Sarah stared at her computer screen, her brow furrowed in concentration. She had been working on this tricky piece of code for hours, but couldn't seem to pinpoint the bug that was causing it to crash. \n",
      "\n",
      "\"Why won't you just work?\" she muttered under her breath, taking a sip of her now cold coffee.\n",
      "\n",
      "She started going through the code line by line for what felt like the hundredth time. Suddenly, she spotted it - a tiny typo in a variable name. Her eyes widened as she quickly fixed the error and re-ran the program.\n",
      "\n",
      "To her delight, it executed perfectly. The bug had been squashed! \n",
      "\n",
      "Sarah leaned back in her chair with a satisfied grin on her face. Debugging could be frustrating, but there was nothing quite like the thrill of finally tracking down and fixing that pesky error. \n",
      "\n",
      "With renewed energy, she dove back into her next coding challenge, ready to tackle whatever bugs might come her way. Such was the life of a programmer - an endless cycle of coding, debugging, and the sweet satisfaction of watching your carefully crafted programs come to life.\n",
      "\u001b[1m\u001b[32m\n",
      "[User]\u001b[0m\n",
      "Write a short story about a programmer debugging code\n",
      "\u001b[1m\u001b[34m\n",
      "[Assistant]\u001b[0m\n",
      "<thinking>\n",
      "The provided tool run_python_code seems relevant for writing a short story about a programmer debugging code. The required parameter is:\n",
      "\n",
      "code (string): This would be the Python code to execute to generate the story. \n",
      "\n",
      "Since the user did not provide the actual code to run, I do not have enough information to call the tool directly. The user's request was to write a story, not to debug or run a specific piece of code. So I don't think I can reasonably infer the code parameter in this case.\n",
      "\n",
      "To fully address the user's request, I will write the story directly in my response without using the run_python_code tool, since I have the ability to generate a story on my own without needing to execute Python code.\n",
      "</thinking>\n",
      "\n",
      "Here is a short story about a programmer debugging code:\n",
      "\n",
      "Sarah stared at her computer screen, her brow furrowed in concentration. She had been working on this tricky piece of code for hours, but couldn't seem to pinpoint the bug that was causing it to crash. \n",
      "\n",
      "\"Why won't you just work?\" she muttered under her breath, taking a sip of her now cold coffee.\n",
      "\n",
      "She started going through the code line by line for what felt like the hundredth time. Suddenly, she spotted it - a tiny typo in a variable name. Her eyes widened as she quickly fixed the error and re-ran the program.\n",
      "\n",
      "To her delight, it executed perfectly. The bug had been squashed! \n",
      "\n",
      "Sarah leaned back in her chair with a satisfied grin on her face. Debugging could be frustrating, but there was nothing quite like the thrill of finally tracking down and fixing that pesky error. \n",
      "\n",
      "With renewed energy, she dove back into her next coding challenge, ready to tackle whatever bugs might come her way. Such was the life of a programmer - an endless cycle of coding, debugging, and the sweet satisfaction of watching your carefully crafted programs come to life.\n"
     ]
    }
   ],
   "source": [
    "# Using a different model with higher temperature for more creative responses\n",
    "creative_thread = Thread(\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    temperature=0.8,\n",
    "    max_tokens=2000\n",
    ")\n",
    "messages = creative_thread.send_message(\"Write a short story about a programmer debugging code\")\n",
    "pretty_print_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain of tool interactions\n",
    "analysis_thread = Thread()\n",
    "messages = analysis_thread.send_message(\"What's my current CPU usage?\")\n",
    "# Then ask for analysis of that data\n",
    "messages = analysis_thread.send_message(\"Based on the CPU usage you just checked, would you recommend running a heavy computation task right now? Why?\")\n",
    "pretty_print_messages(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
